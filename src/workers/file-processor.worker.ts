/**
 * File Processor Worker
 *
 * Backpressure ì œì–´ ë° íŒŒì¼ ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” ì›Œì»¤
 * - Credit-based Flow Control êµ¬í˜„
 * - Water Mark ê¸°ë°˜ ë©”ëª¨ë¦¬ ê´€ë¦¬
 * - WASMì„ í†µí•œ ê³ ì„±ëŠ¥ ë°ì´í„° ì²˜ë¦¬
 */

import initPonsCore from 'pons-core-wasm';
import { WasmReorderingBuffer } from '../services/wasmReorderingBuffer';

// ì„¤ì •ê°’
const HIGH_WATER_MARK = 16 * 1024 * 1024; // 16MB (ì´ ì´ìƒ ìŒ“ì´ë©´ PAUSE ìš”ì²­)
const LOW_WATER_MARK = 4 * 1024 * 1024; // 4MB (ì´ ë°‘ìœ¼ë¡œ ë–¨ì–´ì§€ë©´ RESUME ìš”ì²­)
const BATCH_THRESHOLD = 8 * 1024 * 1024; // 8MB (ë°°ì¹˜ ì²˜ë¦¬ ì„ê³„ê°’)

// ìƒíƒœ íƒ€ì… ì •ì˜
interface WorkerStatus {
  type: 'PAUSE' | 'RESUME' | 'PROGRESS' | 'ERROR' | 'INITIALIZED';
  loaded: number;
  queueSize?: number;
  error?: string;
}

// ë‚´ë¶€ ìƒíƒœ
let fileHandle: FileSystemFileHandle | null = null;
let writable: FileSystemWritableFileStream | null = null;
let reorderingBuffer: WasmReorderingBuffer | null = null;
let currentQueueSize = 0;
let isPaused = false;
let processedOffset = 0;
let totalSize = 0;
let isInitialized = false;

// ë©”ì¸ ìŠ¤ë ˆë“œë¡œ ìƒíƒœë¥¼ ë³´ë‚´ê¸° ìœ„í•œ ì½œë°±
let statusCallback: ((status: WorkerStatus) => void) | null = null;

// ë°°ì¹˜ ì²˜ë¦¬ìš© ë²„í¼
let writeBuffer: Uint8Array[] = [];
let currentBatchSize = 0;

/**
 * ì´ˆê¸°í™” í•¨ìˆ˜
 */
async function init(
  handle: FileSystemFileHandle,
  cb: (status: WorkerStatus) => void,
  fileSize: number
): Promise<void> {
  try {
    fileHandle = handle;
    writable = await fileHandle.createWritable({ keepExistingData: false });
    statusCallback = cb;
    totalSize = fileSize;

    // WASM ì´ˆê¸°í™”
    await initPonsCore();
    reorderingBuffer = new WasmReorderingBuffer();
    await reorderingBuffer.initialize(0);

    isInitialized = true;

    statusCallback?.({
      type: 'INITIALIZED',
      loaded: 0,
      queueSize: 0,
    });

    console.log('[Worker] Initialized & WASM Ready');
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error);
    console.error('[Worker] Initialization failed:', error);
    statusCallback?.({
      type: 'ERROR',
      loaded: 0,
      error: errorMsg,
    });
    throw error;
  }
}

/**
 * ì²­í¬ ìˆ˜ì‹  ë° ì²˜ë¦¬ (Backpressure í•µì‹¬ ë¡œì§)
 */
async function pushChunk(chunk: Uint8Array, offset: number): Promise<void> {
  if (!isInitialized) {
    throw new Error('Worker not initialized');
  }

  // 1. í ì‚¬ì´ì¦ˆ ì¦ê°€
  currentQueueSize += chunk.byteLength;

  // 2. High Water Mark ì²´í¬ -> ë©”ì¸ ìŠ¤ë ˆë“œì— "ê·¸ë§Œ ë³´ë‚´!" ì‹ í˜¸ ì „ì†¡
  if (!isPaused && currentQueueSize > HIGH_WATER_MARK) {
    isPaused = true;
    statusCallback?.({
      type: 'PAUSE',
      loaded: processedOffset,
      queueSize: currentQueueSize,
    });
    console.warn(
      `[Worker] ğŸ›‘ Backpressure triggered (Queue: ${(currentQueueSize / 1024 / 1024).toFixed(2)}MB)`
    );
  }

  try {
    // 3. ìˆœì„œ ì •ë ¬ ë²„í¼ì— ì¶”ê°€
    if (reorderingBuffer) {
      const chunksToWrite = reorderingBuffer.push(
        chunk.buffer.slice(
          chunk.byteOffset,
          chunk.byteOffset + chunk.byteLength
        ) as ArrayBuffer,
        offset
      );

      // 4. ë°°ì¹˜ ë²„í¼ì— ì ì¬
      for (const chunkToWrite of chunksToWrite) {
        const data = new Uint8Array(chunkToWrite);
        writeBuffer.push(data);
        currentBatchSize += data.byteLength;
      }

      // 5. ë°°ì¹˜ ì„ê³„ê°’ ë„ë‹¬ ì‹œ ë””ìŠ¤í¬ì— ì“°ê¸°
      if (currentBatchSize >= BATCH_THRESHOLD) {
        await flushWriteBuffer();
      }
    }
  } catch (err) {
    console.error('[Worker] Processing error:', err);
    const errorMsg = err instanceof Error ? err.message : String(err);
    statusCallback?.({
      type: 'ERROR',
      loaded: processedOffset,
      error: errorMsg,
    });
    throw err;
  } finally {
    // 6. ì²˜ë¦¬ ì™„ë£Œ í›„ í ì‚¬ì´ì¦ˆ ê°ì†Œ
    currentQueueSize -= chunk.byteLength;

    // 7. Low Water Mark ì²´í¬ -> ë©”ì¸ ìŠ¤ë ˆë“œì— "ë‹¤ì‹œ ë³´ë‚´!" ì‹ í˜¸ ì „ì†¡
    if (isPaused && currentQueueSize < LOW_WATER_MARK) {
      isPaused = false;
      statusCallback?.({
        type: 'RESUME',
        loaded: processedOffset,
        queueSize: currentQueueSize,
      });
      console.log('[Worker] â–¶ï¸ Resuming (Queue drained)');
    }

    // 8. ì§„í–‰ë¥  ë³´ê³  (ì“°ë¡œí‹€ë§ ì ìš©)
    statusCallback?.({
      type: 'PROGRESS',
      loaded: processedOffset,
      queueSize: currentQueueSize,
    });
  }
}

/**
 * ë°°ì¹˜ ë²„í¼ë¥¼ ë””ìŠ¤í¬ì— í”ŒëŸ¬ì‹œ
 */
async function flushWriteBuffer(): Promise<void> {
  if (writeBuffer.length === 0 || !writable) return;

  try {
    // í° ë²„í¼ í•˜ë‚˜ë¡œ ë³‘í•©
    const mergedBuffer = new Uint8Array(currentBatchSize);
    let offset = 0;
    for (const chunk of writeBuffer) {
      mergedBuffer.set(chunk, offset);
      offset += chunk.byteLength;
    }

    // OPFS ì“°ê¸°
    await writable.write({
      type: 'write',
      position: processedOffset,
      data: mergedBuffer,
    });

    // ìƒíƒœ ì—…ë°ì´íŠ¸
    processedOffset += currentBatchSize;
    writeBuffer = [];
    currentBatchSize = 0;

    console.debug(
      `[Worker] Flushed ${formatBytes(offset)} to disk, total: ${formatBytes(processedOffset)}`
    );
  } catch (error) {
    console.error('[Worker] Flush error:', error);
    throw error;
  }
}

/**
 * ìµœì¢…í™” í•¨ìˆ˜
 */
async function finalize(): Promise<void> {
  if (!isInitialized) return;

  try {
    // ë‚¨ì€ ë°ì´í„° ëª¨ë‘ í”ŒëŸ¬ì‹œ
    await flushWriteBuffer();

    // íŒŒì¼ ì“°ê¸° ì™„ë£Œ
    if (writable) {
      await writable.close();
      writable = null;
    }

    // ë²„í¼ ì •ë¦¬
    if (reorderingBuffer) {
      reorderingBuffer.clear();
      reorderingBuffer = null;
    }

    console.log('[Worker] Finalization complete');
  } catch (error) {
    console.error('[Worker] Finalization error:', error);
    throw error;
  }
}

/**
 * ì •ë¦¬ í•¨ìˆ˜
 */
async function cleanup(): Promise<void> {
  try {
    await finalize();

    if (writable) {
      await writable.abort();
      writable = null;
    }

    fileHandle = null;
    isInitialized = false;
    currentQueueSize = 0;
    isPaused = false;
    processedOffset = 0;
    totalSize = 0;

    console.log('[Worker] Cleanup complete');
  } catch (error) {
    console.error('[Worker] Cleanup error:', error);
  }
}

/**
 * í˜„ì¬ ìƒíƒœ ì¡°íšŒ
 */
function getStatus(): {
  queueSize: number;
  isPaused: boolean;
  processedOffset: number;
  totalSize: number;
  isInitialized: boolean;
} {
  return {
    queueSize: currentQueueSize,
    isPaused,
    processedOffset,
    totalSize,
    isInitialized,
  };
}

// í—¬í¼ í•¨ìˆ˜
function formatBytes(bytes: number, decimals = 2): string {
  if (bytes === 0) return '0 Bytes';
  const k = 1024;
  const dm = decimals < 0 ? 0 : decimals;
  const sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB'];
  const i = Math.floor(Math.log(bytes) / Math.log(k));
  return parseFloat((bytes / Math.pow(k, i)).toFixed(dm)) + ' ' + sizes[i];
}

// Worker ë©”ì‹œì§€ í•¸ë“¤ëŸ¬
self.onmessage = async (event: MessageEvent) => {
  const { type, payload, id } = event.data;

  try {
    let result;

    switch (type) {
      case 'init':
        result = await init(payload.handle, payload.callback, payload.fileSize);
        break;

      case 'pushChunk':
        result = await pushChunk(payload.chunk, payload.offset);
        break;

      case 'finalize':
        result = await finalize();
        break;

      case 'cleanup':
        result = await cleanup();
        break;

      case 'getStatus':
        result = getStatus();
        break;

      default:
        throw new Error(`Unknown message type: ${type}`);
    }

    // ì„±ê³µ ì‘ë‹µ
    self.postMessage({
      type: 'response',
      id,
      success: true,
      result,
    });
  } catch (error) {
    // ì—ëŸ¬ ì‘ë‹µ
    self.postMessage({
      type: 'response',
      id,
      success: false,
      error: error instanceof Error ? error.message : String(error),
    });
  }
};
